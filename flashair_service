#!/usr/bin/python3

import argparse, urllib.request, sys, csv, datetime, sqlite3, sys
from os.path import expanduser, exists, basename, dirname, getsize
from os import makedirs, SEEK_END
from subprocess import run, DEVNULL, STDOUT, PIPE
from shutil import which, move
from socket import timeout as SocketTimeoutError
from time import sleep


parser = argparse.ArgumentParser()
parser.add_argument(dest="flashair_ip", nargs='?', default="flashair")
parser.add_argument("-s", "--source-folder", default=["/DCIM", "/PRIVATE/AVCHD/BDMV/STREAM"], action='append')
parser.add_argument("-d", "--dest-folder", default=expanduser("~/FlashAir"))
parser.add_argument("-c", "--cleanup-percent", type=float, help="Percentage of space to keep free", default=-1)
parser.add_argument("-v", "--verbosity", help="increase output verbosity", action="count", default=0)
parser.add_argument("-f", "--force", help="skip check for changes, this will cause extra traffic/stress", action="store_true")
parser.add_argument("--daemon", help="Run in a continuous loop", action="store_true")
group = parser.add_mutually_exclusive_group()
group.add_argument("--progress", dest="progress", help="Print progress for file transfers (default without --daemon)", action="store_true")
group.add_argument("--no-progress", dest="progress", help="Do not print progress for file transfers (default for --daemon)", action="store_false")
parser.add_argument("-i", "--interval", type=int, help="Seconds to wait between attempts if running as daemon", default=20)
args = parser.parse_args()

# default level for non-daemon is 1
if not args.daemon:
    args.verbosity += 1

def debug(message, level=1):
    if level <= args.verbosity:
        print(message)

debug("Command line arguments: {}".format(args), 3)
show_progress = args.progress if args.progress else (not args.daemon)
tz = datetime.timezone.utc
forceUpdate = False
TIMEOUT = 5.0 # seconds
CHUNK_SIZE = 25*1024 # KB
CSV_LIST_FIELDS = ['dir', 'name', 'size', 'attr', 'date', 'time']

#    id INTEGER PRIMARY KEY AUTOINCREMENT,

#sqlite transferred db
makedirs(args.dest_folder, exist_ok=True)
conn = sqlite3.connect(args.dest_folder + "/.transferred.db")
conn.execute("""CREATE TABLE IF NOT EXISTS  transferred (
    file TEXT NOT NULL,
    timestamp DATETIME NOT NULL,
    size INTEGER DEFAULT 0,
    PRIMARY KEY (file, timestamp)
    );""")
cursor = conn.cursor()


# Find commands
jhead = which("jhead")
exiftool = which("exiftool")
fping = which("fping")
if fping:
    ping = [fping, "-r 0", args.flashair_ip]
else:
    ping = [which("ping"), "-c 1", args.flashair_ip]



def alive():
    data = run(ping, stdout=DEVNULL, stderr=STDOUT).returncode
    alive = (data == 0)
    if alive:
        debug("Ping success: {}".format(args.flashair_ip), 3)
    else:
        debug("Ping failure: {}".format(args.flashair_ip), 3)
    return alive

def faCommand(encoded_url, data=None):
    command = "http://" + args.flashair_ip + "/" + encoded_url
    debug("Sending: " + command, 2)
    try:
        reader = urllib.request.urlopen(command)
    except Exception:
        pass
        raise Exception("Command Failed")

    #return data
    data = reader.read().decode('utf-8')
    debug(data, 3)
    return data

def faTimeZone():
    try:
        data = faCommand("command.cgi?op=221")
    except Exception:
        return datetime.timezone.utc
    delta = datetime.timedelta(minutes=int(data)*15)
    return datetime.timezone(delta)


def faFree():
    data = faCommand("command.cgi?op=140")
    sectors,bytes_per = data.split(",")
    free,total = sectors.split("/")
    bytes_per = int(bytes_per)
    free = int(free)
    total = int(total)
    return {'percent' : free/total*100, 'free' : free*bytes_per, 'total' : total*bytes_per}

def faDelete(filename):
    result = faCommand("upload.cgi?DEL={}".format(filename));
    debug("Deleting {}. Result: {}".format(filename, result))
    return (result == "SUCCESS")

def faUpdated():
    return faCommand("command.cgi?op=102") == "1"

def faList(dir="/"):
    data = []
    try:
        raw = faCommand("command.cgi?op=100&DIR=" + dir)
        lines = raw.splitlines()
        first = lines.pop(0)
        if first != "WLANSD_FILELIST":
            raise Exception("Invalid file list data")

        reader = csv.DictReader(lines, CSV_LIST_FIELDS)
        data = list(reader)
        return data
    except urllib.error.HTTPError as e:
        if "HTTP Error 404" in str(e):
            raise FileNotFoundError(str(e))

def parseDate(data):
    data = int(data)
    day = (data & 0b0000000000011111);
    month = (data & 0b0000000111100000) >> 5;
    year= ((data & 0b1111111000000000) >> 9) + 1980;
    return datetime.date(year, month, day)

def parseTime(data):
    data = int(data)
    seconds = (data & 0b0000000000011111) * 2;
    minutes = (data & 0b0000011111100000) >> 5;
    hours = (data & 0b1111100000000000) >> 11;
    return datetime.time(hours, minutes, seconds, 0, tz)

def tempFile(src_path):
    return "/tmp/" + src_path.lstrip("/").replace("/", "_")

def checkDownloaded(file):
    cursor.execute("SELECT file FROM transferred WHERE file=? AND timestamp=?", (file['src_path'], file['datetime'].timestamp()))
    row = cursor.fetchone()
    return row != None

def rotateFile(filename):
    if jhead:
        debug("Automatically correcting orientation", 2)
        proc = run([jhead, "-autorot", "-ft", filename], stdout=DEVNULL, stderr=STDOUT)
        debug(" ".join(proc.args), 3)
        return True
    return False

def renameFile(file):
    dest = None
    if exiftool:
        debug("Renaming file based on exif data", 2)
        proc = run([exiftool, "-p", "$DateTimeOriginal", "-d", "/%Y-%m/%Y-%m_%d-%H:%M:%S_", file['temp_file']], stdout=PIPE, stderr=DEVNULL)
        debug(format(proc), 3)
        rel_dir = proc.stdout.decode().strip()
        if rel_dir:
            dest = args.dest_folder + rel_dir + file['name']

    if not dest:
        debug("Renaming file based on file creation date", 2)
        dest = "{}/{}_{}".format(args.dest_folder, file['datetime'].strftime("%Y-%m/%Y-%m-%d_%H:%M:%S"), file['name'])

    makedirs(dirname(dest), exist_ok=True)
    if exists(dest):
        raise FileExistsError("Destination file exists: {}".format(dest))
    move(file['temp_file'], dest)
    return dest

def print_progress(ratio):
    count = int(ratio * 20)
    sys.stdout.write('\r')
    sys.stdout.write("[{:<20}] {:.2f}%".format('='*count, 100*ratio))
    sys.stdout.flush()


def transferFile(file):
    src = "http://" + args.flashair_ip + file['src_path']
    tmp = file['temp_file']
    file_size = int(file['size'])
    request = urllib.request.Request(src)

    bytes_read = 0
    if exists(tmp):
        # resume transfer with an http range request
        bytes_read = getsize(tmp)
        request.add_header('Range', 'bytes={}-'.format(bytes_read))

    # The file might be complete, skip downloading it if it is
    if bytes_read < file_size:
        stream = urllib.request.urlopen(request, timeout=TIMEOUT)
        with open(tmp, 'ab') as f:
            while(bytes_read < file_size):
                chunk = stream.read(CHUNK_SIZE)
                chunk_len = len(chunk)
                if chunk_len == CHUNK_SIZE or bytes_read + chunk_len == file_size:
                    bytes_read += len(chunk)
                    f.write(chunk)
                    if show_progress:
                        print_progress(bytes_read / file_size)
                else:
                    raise IOError("Partial chunk")

            if show_progress:
                print() # print line return after progress bar

    debug("Inserting into transferred db: {} {:.0f} {}".format(file['src_path'], file['datetime'].timestamp(), file['size']), 2)
    cursor.execute("INSERT INTO transferred values(?,?,?)", (file['src_path'], int(file['datetime'].timestamp()), file['size']))
    conn.commit() # make sure the db is saved in case we get interrupted
    debug("Inserted: {}".format(cursor.lastrowid), 3)

def syncFile(file):
    global forceUpdate
    try:
        if not checkDownloaded(file):
            debug(file, 3)
            print("Transferring file: {}".format(file['src_path']))
            transferFile(file)
            rotateFile(file['temp_file'])
            file['dest_path'] = renameFile(file)
            print("Saved to: {}".format(file['dest_path']))
                
    except (SocketTimeoutError, IOError) as e:
        if show_progress:
            print() # print line return after progress bar
        print("Transfer interrupted: {}".format(e))
        forceUpdate = True
    except FileExistsError as e:
        print(str(e))


def syncDir(dir):
    files = faList(dir)
    debug(files, 4)
    
    for file in files:
        file['src_path'] = file['dir'].rstrip("/") + "/" + file['name']
        if int(file['attr']) & 16:
            # bit 5 = dir, recurse into dir
            syncDir(file['src_path'])
            continue
        file['temp_file'] = tempFile(file['src_path'])
        file['datetime'] = datetime.datetime.combine(parseDate(file['date']), parseTime(file['time']))

        syncFile(file)

def cleanup():
    free = faFree()
    debug(free, 3)
    debug("Free space: {:,.3f} GiB".format(free['free'] / 1073741824), 2)
    if free['percent'] < args.cleanup_percent:
        goal = free['total'] * args.cleanup_percent / 100
        needed = goal - free['free']
        deleted = []
        freed = 0
        debug("{:.2f}% free, performing cleanup.  Attempting to free {:,.2f} MiB of data.".format(free['percent'], needed / 1048576))
        cursor.execute("SELECT ROWID, file, size FROM transferred ORDER BY timestamp")
        for row in cursor:
            success = faDelete(row[1])
            deleted.append(row[0])
            if success:
                freed += row[2]
            if freed > needed:
                break

        # remove deleted (or non-existent) files from the db
        query = "DELETE from transferred WHERE ROWID IN ({seq})".format(seq=','.join(['?']*len(deleted)))
        cursor.execute(query, deleted)
        conn.commit()
        debug("[SQL] {} {}".format(query, deleted) , 4)


print("Starting " + basename(__file__) + "...")
print("Syncing " + str(args.source_folder) + " from " + args.flashair_ip)

while True:
    if alive():
        debug("FlashAir card found!")
        if forceUpdate or args.force or faUpdated():
            forceUpdate = False
            tz = faTimeZone()

            for folder in args.source_folder:
                syncDir(folder)

        if args.cleanup_percent > 0:
            cleanup()

    elif not args.daemon or args.verbosity > 0:
        # don't spam the logs when daemonized, but be friendly to humans
        print("FlashAir card ({}) not pingable".format(args.flashair_ip))

    # only run once by default, if --daemon loop
    if not args.daemon:
        break

    # wait so we don't monopolize the CPU
    sleep(args.interval)


# save sqlite and close
conn.commit()
conn.close()

